{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a5215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# === –ù–ê–î–ï–ñ–ù–û–ï –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–£–¢–ï–ô ===\n",
    "NOTEBOOK_DIR = Path(os.getcwd()).resolve()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "DATA_DIR = PROJECT_ROOT / \"Data\"\n",
    "\n",
    "DATA_RAW = DATA_DIR / \"data_raw.csv\"\n",
    "FINAL_XLSX = DATA_DIR / \"final_results_to_analyze.xlsx\"\n",
    "\n",
    "print(\"üìÅ Notebook dir :\", NOTEBOOK_DIR)\n",
    "print(\"üìÅ Project root :\", PROJECT_ROOT)\n",
    "print(\"üìÅ Data folder  :\", DATA_DIR)\n",
    "print(\"üìÑ Raw CSV      :\", DATA_RAW)\n",
    "print(\"üìÑ Final XLSX   :\", FINAL_XLSX)\n",
    "\n",
    "missing = []\n",
    "if not DATA_RAW.exists(): missing.append(str(DATA_RAW))\n",
    "if not FINAL_XLSX.exists(): missing.append(str(FINAL_XLSX))\n",
    "if missing:\n",
    "    raise FileNotFoundError(\"‚ùå –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã:\\\\n\" + \"\\\\n\".join(missing))\n",
    "\n",
    "print(\"‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba6457e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ –¢–µ–∫—É—â–∞—è —Ä–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: c:\\ZC\\finish\\notebooks\n",
      "üìÅ –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞: c:\\ZC\\finish\\notebooks\n",
      "üìÅ –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º: c:\\ZC\\finish\\notebooks\\Data\\data_raw.csv\n",
      "üìÅ –ü—É—Ç—å –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: c:\\ZC\\finish\\notebooks\\Data\\final_results_to_analyze.xlsx\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\ZC\\\\finish\\\\notebooks\\\\Data\\\\data_raw.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìÅ –ü—É—Ç—å –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFINAL_XLSX\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_RAW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã:\u001b[39m\u001b[33m\"\u001b[39m, data.shape)\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(data[\u001b[33m'\u001b[39m\u001b[33mevent_type\u001b[39m\u001b[33m'\u001b[39m].value_counts())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'c:\\\\ZC\\\\finish\\\\notebooks\\\\Data\\\\data_raw.csv'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from scipy.stats import ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# =========================\n",
    "# 0. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—É—Ç–µ–π –∫ –¥–∞–Ω–Ω—ã–º –ø—Ä–æ–µ–∫—Ç–∞\n",
    "# =========================\n",
    "current_dir = os.path.abspath(os.getcwd())\n",
    "BASE_DIR = current_dir\n",
    "\n",
    "max_levels = 5\n",
    "for _ in range(max_levels):\n",
    "    if os.path.exists(os.path.join(BASE_DIR, \"Data\")):\n",
    "        break\n",
    "    parent_dir = os.path.dirname(BASE_DIR)\n",
    "    if parent_dir == BASE_DIR:\n",
    "        break\n",
    "    BASE_DIR = parent_dir\n",
    "\n",
    "if not os.path.exists(os.path.join(BASE_DIR, \"Data\")):\n",
    "    BASE_DIR = os.path.abspath(os.path.join(current_dir, os.pardir, os.pardir))\n",
    "\n",
    "DATA_RAW = os.path.join(BASE_DIR, \"Data\", \"data_raw.csv\")\n",
    "FINAL_XLSX = os.path.join(BASE_DIR, \"Data\", \"final_results_to_analyze.xlsx\")\n",
    "\n",
    "print(f\"üìÅ –¢–µ–∫—É—â–∞—è —Ä–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}\")\n",
    "print(f\"üìÅ –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞: {BASE_DIR}\")\n",
    "print(f\"üìÅ –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º: {DATA_RAW}\")\n",
    "print(f\"üìÅ –ü—É—Ç—å –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: {FINAL_XLSX}\")\n",
    "\n",
    "# =========================\n",
    "# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "# =========================\n",
    "data = pd.read_csv(DATA_RAW, parse_dates=['dt'])\n",
    "print(\"–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã:\", data.shape)\n",
    "print(data['event_type'].value_counts())\n",
    "\n",
    "# =========================\n",
    "# 2. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –≤–æ—Ä–æ–Ω–∫—É\n",
    "# =========================\n",
    "df_pivot = data.pivot_table(index=['dt','client_id'],\n",
    "                            columns='event_type',\n",
    "                            aggfunc='size',\n",
    "                            fill_value=0).reset_index()\n",
    "df_pivot.columns.name = None\n",
    "df_pivot = df_pivot.rename(columns={'view':'views','click':'clicks','add':'adds'})\n",
    "df_pivot['views'] = (df_pivot['views']>0).astype(int)\n",
    "df_pivot['clicks'] = (df_pivot['clicks']>0).astype(int)\n",
    "df_pivot['adds'] = (df_pivot['adds']>0).astype(int)\n",
    "\n",
    "# =========================\n",
    "# 3. –†–∞—Å—á—ë—Ç CTR –∏ CR –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é\n",
    "# =========================\n",
    "user_summary = df_pivot.groupby('client_id').agg({\n",
    "    'views':'sum',\n",
    "    'clicks':'sum',\n",
    "    'adds':'sum'\n",
    "}).reset_index()\n",
    "\n",
    "user_summary['CTR'] = user_summary['clicks']/user_summary['views']\n",
    "user_summary['CR'] = user_summary['adds']/user_summary['clicks']\n",
    "\n",
    "# =========================\n",
    "# 4. –î–µ–ª—å—Ç–∞-–º–µ—Ç–æ–¥ –¥–ª—è ratio-–º–µ—Ç—Ä–∏–∫\n",
    "# =========================\n",
    "def var_ratio(x, y):\n",
    "    mean_x = np.mean(x)\n",
    "    mean_y = np.mean(y)\n",
    "    var_x = np.var(x, ddof=1)\n",
    "    var_y = np.var(y, ddof=1)\n",
    "    cov_xy = np.cov(x,y, ddof=1)[0][1]\n",
    "    return var_x/mean_y**2 + var_y*mean_x**2/mean_y**4 - 2*mean_x*cov_xy/mean_y**3\n",
    "\n",
    "var_CR = var_ratio(user_summary['adds'], user_summary['clicks'])\n",
    "var_CTR = var_ratio(user_summary['clicks'], user_summary['views'])\n",
    "print(\"–î–∏—Å–ø–µ—Ä—Å–∏—è CR:\", var_CR)\n",
    "print(\"–î–∏—Å–ø–µ—Ä—Å–∏—è CTR:\", var_CTR)\n",
    "\n",
    "# =========================\n",
    "# 5. –†–∞—Å—á—ë—Ç MDE\n",
    "# =========================\n",
    "def get_MDE(mu, std, sample_size, n_groups=2, target_share=0.5, r=1, alpha=0.05, beta=0.2):\n",
    "    t_alpha = stats.norm.ppf(1 - ((alpha / 2)), loc=0, scale=1)\n",
    "    comparisons = n_groups - 1\n",
    "    t_beta = stats.norm.ppf(1 - beta, loc=0, scale=1)\n",
    "    sample_ratio_correction = r+2+1/r\n",
    "    mde = np.sqrt(sample_ratio_correction)*(t_alpha + t_beta) * std / np.sqrt(sample_size*(1-target_share*(comparisons-1)))\n",
    "    return mde, mde*100/mu\n",
    "\n",
    "mu_CR = user_summary['CR'].mean()\n",
    "std_CR = np.sqrt(var_CR)\n",
    "sample_size = int(0.2*len(user_summary))  # ‚â§20% –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "\n",
    "mde_abs, mde_pct = get_MDE(mu_CR, std_CR, sample_size)\n",
    "print(f\"MDE –¥–ª—è CR: {mde_abs:.4f} ({mde_pct:.2f}%) –ø—Ä–∏ {sample_size} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è—Ö\")\n",
    "\n",
    "# =========================\n",
    "# 6. –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "# =========================\n",
    "results = pd.read_excel(FINAL_XLSX)\n",
    "print(\"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞:\", results.shape)\n",
    "\n",
    "user_exp = results.groupby(['client_id','ab_group']).agg({\n",
    "    'is_view_ads':'max',\n",
    "    'cnt_view_ads':'sum',\n",
    "    'is_adds_ads':'max',\n",
    "    'cnt_adds_ads':'sum',\n",
    "    'sum_adds_ads':'sum',\n",
    "    'is_orders_ads':'max',\n",
    "    'cnt_orders_ads':'sum',\n",
    "    'sum_orders_ads':'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# =========================\n",
    "# 7. –†–∞—Å—á—ë—Ç –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ –ø–æ –≥—Ä—É–ø–ø–∞–º\n",
    "# =========================\n",
    "metrics = user_exp.groupby('ab_group').agg({\n",
    "    'cnt_view_ads':'sum',\n",
    "    'cnt_adds_ads':'sum',\n",
    "    'sum_adds_ads':'sum',\n",
    "    'cnt_orders_ads':'sum',\n",
    "    'sum_orders_ads':'sum',\n",
    "    'client_id':'nunique'\n",
    "}).rename(columns={'client_id':'users'}).reset_index()\n",
    "\n",
    "metrics['CTR'] = metrics['cnt_adds_ads'] / metrics['cnt_view_ads']\n",
    "metrics['CR_adds'] = metrics['cnt_adds_ads'] / metrics['cnt_view_ads']\n",
    "metrics['ARPU'] = metrics['sum_adds_ads'] / metrics['users']\n",
    "metrics['ARPPU'] = metrics['sum_adds_ads'] / metrics['cnt_adds_ads']\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "# =========================\n",
    "# 8. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "# =========================\n",
    "sns.barplot(x='ab_group', y='CR_adds', data=metrics)\n",
    "plt.title('–ö–æ–Ω–≤–µ—Ä—Å–∏—è –≤ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –≥—Ä—É–ø–ø–∞–º')\n",
    "plt.show()\n",
    "\n",
    "sns.barplot(x='ab_group', y='ARPU', data=metrics)\n",
    "plt.title('ARPU –ø–æ –≥—Ä—É–ø–ø–∞–º')\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# 9. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞\n",
    "# =========================\n",
    "control = user_exp[user_exp['ab_group']=='A']\n",
    "test = user_exp[user_exp['ab_group']=='B']\n",
    "\n",
    "# Z-—Ç–µ—Å—Ç CR\n",
    "success = np.array([control['cnt_adds_ads'].sum(), test['cnt_adds_ads'].sum()])\n",
    "nobs = np.array([control['cnt_view_ads'].sum(), test['cnt_view_ads'].sum()])\n",
    "stat, pval = proportions_ztest(success, nobs)\n",
    "print(f\"Z-—Ç–µ—Å—Ç CR: stat={stat:.4f}, p-value={pval:.4f}\")\n",
    "\n",
    "# Z-—Ç–µ—Å—Ç CTR\n",
    "success_ctr = np.array([control['cnt_adds_ads'].sum(), test['cnt_adds_ads'].sum()])\n",
    "nobs_ctr = np.array([control['cnt_view_ads'].sum(), test['cnt_view_ads'].sum()])\n",
    "stat_ctr, pval_ctr = proportions_ztest(success_ctr, nobs_ctr)\n",
    "print(f\"Z-—Ç–µ—Å—Ç CTR: stat={stat_ctr:.4f}, p-value={pval_ctr:.4f}\")\n",
    "\n",
    "# t-—Ç–µ—Å—Ç ARPU\n",
    "stat_arpu, pval_arpu = ttest_ind(control['sum_adds_ads'], test['sum_adds_ads'], equal_var=False)\n",
    "print(f\"T-—Ç–µ—Å—Ç ARPU: stat={stat_arpu:.4f}, p-value={pval_arpu:.4f}\")\n",
    "\n",
    "# t-—Ç–µ—Å—Ç ARPPU\n",
    "control_arppu = control['sum_adds_ads']/control['cnt_adds_ads']\n",
    "test_arppu = test['sum_adds_ads']/test['cnt_adds_ads']\n",
    "stat_arppu, pval_arppu = ttest_ind(control_arppu.dropna(), test_arppu.dropna(), equal_var=False)\n",
    "print(f\"T-—Ç–µ—Å—Ç ARPPU: stat={stat_arppu:.4f}, p-value={pval_arppu:.4f}\")\n",
    "\n",
    "# =========================\n",
    "# 10. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ markdown –æ—Ç—á–µ—Ç–∞\n",
    "# =========================\n",
    "with open('finalgpt5.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ A/B —Ç–µ—Å—Ç—É —Ä–µ–∫–ª–∞–º–Ω–æ–≥–æ –±–ª–æ–∫–∞\\n\\n\")\n",
    "    f.write(\"## 1. –î–∏–∑–∞–π–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\\n\")\n",
    "    f.write(f\"- –ö–ª—é—á–µ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞: CR (–∫–æ–Ω–≤–µ—Ä—Å–∏—è –≤ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–∑ —Ä–µ–∫–ª–∞–º—ã)\\n\")\n",
    "    f.write(f\"- –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {mu_CR:.4f}\\n\")\n",
    "    f.write(f\"- –î–∏—Å–ø–µ—Ä—Å–∏—è: {var_CR:.6f}\\n\")\n",
    "    f.write(f\"- MDE: {mde_abs:.4f} ({mde_pct:.2f}%)\\n\")\n",
    "    f.write(f\"- –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏: {sample_size} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\\n\\n\")\n",
    "\n",
    "    f.write(\"## 2. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\\n\")\n",
    "    f.write(metrics.to_markdown())\n",
    "\n",
    "    f.write(\"\\n\\n## 3. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\\n\")\n",
    "    f.write(\"–ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –æ—Ç–¥–µ–ª—å–Ω–æ, –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º seaborn.\\n\")\n",
    "\n",
    "    f.write(\"\\n\\n## 4. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞\\n\")\n",
    "    f.write(f\"- Z-—Ç–µ—Å—Ç CR: stat={stat:.4f}, p-value={pval:.4f}\\n\")\n",
    "    f.write(f\"- Z-—Ç–µ—Å—Ç CTR: stat={stat_ctr:.4f}, p-value={pval_ctr:.4f}\\n\")\n",
    "    f.write(f\"- T-—Ç–µ—Å—Ç ARPU: stat={stat_arpu:.4f}, p-value={pval_arpu:.4f}\\n\")\n",
    "    f.write(f\"- T-—Ç–µ—Å—Ç ARPPU: stat={stat_arppu:.4f}, p-value={pval_arppu:.4f}\\n\")\n",
    "\n",
    "    f.write(\"\\n\\n## 5. –í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\\n\")\n",
    "    if pval < 0.05:\n",
    "        f.write(\"- CR –∑–Ω–∞—á–∏–º–æ –≤—ã—à–µ –≤ —Ç–µ—Å—Ç–æ–≤–æ–π –≥—Ä—É–ø–ø–µ ‚Üí —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å —Ä–µ–∫–ª–∞–º–Ω—ã–π –±–ª–æ–∫ –≤–≤–µ—Ä—Ö.\\n\")\n",
    "    else:\n",
    "        f.write(\"- CR —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –Ω–µ–∑–Ω–∞—á–∏–º ‚Üí –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ —Ä–µ–∫–ª–∞–º–Ω–æ–≥–æ –±–ª–æ–∫–∞ –Ω–µ –¥–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∞.\\n\")\n",
    "    if pval_ctr < 0.05:\n",
    "        f.write(\"- CTR –∑–Ω–∞—á–∏–º–æ –≤—ã—à–µ ‚Üí –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —á–∞—â–µ –∫–ª–∏–∫–∞—é—Ç –ø–æ —Ä–µ–∫–ª–∞–º–µ.\\n\")\n",
    "    if pval_arpu < 0.05:\n",
    "        f.write(\"- ARPU –∑–Ω–∞—á–∏–º–æ –≤—ã—à–µ ‚Üí —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è —Å—Ä–µ–¥–Ω—è—è –≤—ã—Ä—É—á–∫–∞ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\\n\")\n",
    "    if pval_arppu < 0.05:\n",
    "        f.write(\"- ARPPU –∑–Ω–∞—á–∏–º–æ –≤—ã—à–µ ‚Üí —Ä–∞—Å—Ç–µ—Ç –≤—ã—Ä—É—á–∫–∞ –Ω–∞ –ø–ª–∞—Ç—è—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
